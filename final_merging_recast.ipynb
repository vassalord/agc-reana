{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_root = \"histograms_merged.root\"  # will be overridden by papermill -p target_root\n",
    "JSON_FILE = \"nanoaod_inputs.json\"\n",
    "EMPTY_HIST_YIELD = 1.0\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import uproot\n",
    "from uproot.writing.identify import to_TH1x, to_TAxis\n",
    "\n",
    "# Fallback: allow overriding target_root from env if papermill didn't inject parameters\n",
    "_target_from_env = os.environ.get(\"TARGET_ROOT\")\n",
    "if _target_from_env:\n",
    "    target_root = _target_from_env\n",
    "\n",
    "def extract_samples_from_json(json_file):\n",
    "    out = []\n",
    "    with open(json_file, \"r\") as fd:\n",
    "        data = json.load(fd)\n",
    "        for sample, conditions in data.items():\n",
    "            for condition in conditions:\n",
    "                out.append((sample, condition))\n",
    "    return out\n",
    "\n",
    "def list_channel_keys(file_handle, process_tag):\n",
    "    out = {}\n",
    "    for key in file_handle.keys(cycle=False):\n",
    "        name = key.split(\";\")[0]\n",
    "        if name.endswith(\"_\" + process_tag):\n",
    "            channel = name[: -(len(process_tag) + 1)]\n",
    "            out[channel] = name\n",
    "    return out\n",
    "\n",
    "def h_sum_yield(h):\n",
    "    vals, _ = h.to_numpy()\n",
    "    return float(np.nansum(vals))\n",
    "\n",
    "def try_variances(h):\n",
    "    try:\n",
    "        v = h.variances()\n",
    "        if v is not None:\n",
    "            return np.asarray(v)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def build_th1x(vals, edges, name, title, var=None):\n",
    "    vals = np.asarray(vals, dtype=\"float64\")\n",
    "    edges = np.asarray(edges, dtype=\"float64\")\n",
    "    nbins = len(edges) - 1\n",
    "    data = np.zeros(nbins + 2, dtype=\"float64\")\n",
    "    data[1:-1] = vals\n",
    "    if var is None:\n",
    "        sumw2_core = vals.copy()\n",
    "    else:\n",
    "        sumw2_core = np.asarray(var, dtype=\"float64\")\n",
    "    sumw2 = np.zeros(nbins + 2, dtype=\"float64\")\n",
    "    sumw2[1:-1] = sumw2_core\n",
    "    centers = 0.5 * (edges[1:] + edges[:-1])\n",
    "    fEntries = float(np.sum(vals))\n",
    "    fTsumw   = float(np.sum(vals))\n",
    "    fTsumw2  = float(np.sum(sumw2_core))\n",
    "    fTsumwx  = float(np.sum(vals * centers))\n",
    "    fTsumwx2 = float(np.sum(vals * centers**2))\n",
    "    xaxis = to_TAxis(\"xaxis\", \"\", nbins, float(edges[0]), float(edges[-1]), edges)\n",
    "    fMaximum = float(np.max(vals) * 1.2) if np.max(vals) > 0 else 1.0\n",
    "    fMinimum = 0.0\n",
    "    fBarOffset = 0\n",
    "    fBarWidth = 1\n",
    "    try:\n",
    "        return to_TH1x(\n",
    "            name, title, data,\n",
    "            fEntries, fTsumw, fTsumw2, fTsumwx, fTsumwx2,\n",
    "            sumw2, xaxis,\n",
    "            None, None,\n",
    "            None,\n",
    "            fBarOffset, fBarWidth,\n",
    "            fMaximum, fMinimum,\n",
    "        )\n",
    "    except TypeError:\n",
    "        return to_TH1x(\n",
    "            name, title, data,\n",
    "            fEntries, fTsumw, fTsumw2, fTsumwx, fTsumwx2,\n",
    "            sumw2, xaxis\n",
    "        )\n",
    "\n",
    "def get_title_safe(h):\n",
    "    try:\n",
    "        t = h.member(\"fTitle\")\n",
    "        try:\n",
    "            return t.decode() if isinstance(t, (bytes, bytearray)) else str(t)\n",
    "        except Exception:\n",
    "            return str(t)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return h.title\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "# Build the list of inputs\n",
    "items = extract_samples_from_json(JSON_FILE)\n",
    "everything_roots = [f\"everything_merged_{s}__{c}.root\" for (s, c) in items]\n",
    "\n",
    "req_ttbar_me = \"everything_merged_ttbar__ME_var.root\"\n",
    "req_ttbar_ps = \"everything_merged_ttbar__PS_var.root\"\n",
    "req_wjets_no = \"everything_merged_wjets__nominal.root\"\n",
    "\n",
    "# Read existing target (if any)\n",
    "existing_map = {}\n",
    "if os.path.exists(target_root):\n",
    "    with uproot.open(target_root) as f_prev:\n",
    "        for k in f_prev.keys(cycle=False):\n",
    "            name = k.split(\";\")[0]\n",
    "            h = f_prev[k]\n",
    "            vals, edges = h.to_numpy()\n",
    "            var = try_variances(h)\n",
    "            title = get_title_safe(h)\n",
    "            existing_map[name] = (vals, edges, var, title)\n",
    "\n",
    "\n",
    "result_map = dict(existing_map)\n",
    "\n",
    "for h_file in everything_roots:\n",
    "    try:\n",
    "        with uproot.open(h_file) as f_in:\n",
    "            for k in f_in.keys(cycle=False):\n",
    "                name = k.split(\";\")[0]\n",
    "                h = f_in[k]\n",
    "                vals, edges = h.to_numpy()\n",
    "                var = try_variances(h)\n",
    "                title = get_title_safe(h)\n",
    "                result_map[name] = (vals, edges, var, title)  # overwrite policy\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARN] missing: {h_file}\")\n",
    "\n",
    "\n",
    "if all(p in everything_roots for p in (req_ttbar_me, req_ttbar_ps, req_wjets_no)):\n",
    "    with uproot.open(req_ttbar_me) as f_ttbar_ME, \\\n",
    "         uproot.open(req_ttbar_ps) as f_ttbar_PS, \\\n",
    "         uproot.open(req_wjets_no) as f_wjets:\n",
    "\n",
    "        ttbar_me_map = list_channel_keys(f_ttbar_ME, \"ttbar_ME_var\")\n",
    "        ttbar_ps_map = list_channel_keys(f_ttbar_PS, \"ttbar_PS_var\")\n",
    "        wjets_map    = list_channel_keys(f_wjets,    \"wjets_nominal\")\n",
    "        common_channels = sorted(set(ttbar_me_map) & set(ttbar_ps_map) & set(wjets_map))\n",
    "        print(f\"[INFO] channels for pseudodata_nominal: {len(common_channels)}\")\n",
    "\n",
    "        for channel in common_channels:\n",
    "            h_me = f_ttbar_ME[ttbar_me_map[channel]]\n",
    "            h_ps = f_ttbar_PS[ttbar_ps_map[channel]]\n",
    "            h_wj = f_wjets[wjets_map[channel]]\n",
    "\n",
    "            if (\n",
    "                h_sum_yield(h_me) <= EMPTY_HIST_YIELD or\n",
    "                h_sum_yield(h_ps) <= EMPTY_HIST_YIELD or\n",
    "                h_sum_yield(h_wj) <= EMPTY_HIST_YIELD\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            vals_me, edges    = h_me.to_numpy()\n",
    "            vals_ps, edges_ps = h_ps.to_numpy()\n",
    "            vals_wj, edges_wj = h_wj.to_numpy()\n",
    "\n",
    "            if not (np.allclose(edges, edges_ps) and np.allclose(edges, edges_wj)):\n",
    "                print(f\"[WARN] binning mismatch in {channel}, skipping pseudodata for it\")\n",
    "                continue\n",
    "\n",
    "            new_vals = 0.5 * (vals_me + vals_ps) + vals_wj\n",
    "            var_me = try_variances(h_me)\n",
    "            var_ps = try_variances(h_ps)\n",
    "            var_wj = try_variances(h_wj)\n",
    "            new_var = (\n",
    "                0.25 * (var_me + var_ps) + var_wj\n",
    "                if (var_me is not None and var_ps is not None and var_wj is not None)\n",
    "                else None\n",
    "            )\n",
    "            hname  = f\"{channel}_pseudodata_nominal\"\n",
    "            htitle = \"Pseudodata = 0.5*(ttbar_ME + ttbar_PS) + wjets_nominal\"\n",
    "\n",
    "            result_map[hname] = (new_vals, edges, new_var, htitle)\n",
    "\n",
    "\n",
    "ctx = uproot.update if os.path.exists(target_root) else uproot.recreate\n",
    "os.makedirs(os.path.dirname(target_root) or \".\", exist_ok=True)\n",
    "with ctx(target_root) as f_out:\n",
    "    for name, (vals, edges, var, title) in result_map.items():\n",
    "        f_out[name] = build_th1x(vals, edges, name, title or name, var)\n",
    "\n",
    "print(\"[OK] Union-with-overwrite merge finished.\")\n",
    "\n",
    "\n",
    "import os, time\n",
    "for _ in range(20):\n",
    "    if os.path.exists(target_root) and os.path.getsize(target_root) > 0:\n",
    "        print(\"[OK] Verified target_root:\", target_root)\n",
    "        break\n",
    "    time.sleep(0.5)\n",
    "else:\n",
    "    print(\"[WARN] target_root not visible yet:\", target_root)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
