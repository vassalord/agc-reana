{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import uproot\n",
    "from uproot.writing.identify import to_TH1x, to_TAxis\n",
    "\n",
    "JSON_FILE = \"nanoaod_inputs.json\"\n",
    "EMPTY_HIST_YIELD = 1.0\n",
    "\n",
    "def extract_samples_from_json(json_file):\n",
    "    out = []\n",
    "    with open(json_file, \"r\") as fd:\n",
    "        data = json.load(fd)\n",
    "        for sample, conditions in data.items():\n",
    "            for condition in conditions:\n",
    "                out.append((sample, condition))\n",
    "    return out\n",
    "\n",
    "def list_channel_keys(file_handle, process_tag):\n",
    "    out = {}\n",
    "    for key in file_handle.keys(cycle=False):\n",
    "        name = key.split(\";\")[0]\n",
    "        if name.endswith(\"_\" + process_tag):\n",
    "            channel = name[: -(len(process_tag) + 1)]\n",
    "            out[channel] = name\n",
    "    return out\n",
    "\n",
    "def h_sum_yield(h):\n",
    "    vals, _ = h.to_numpy()\n",
    "    return float(np.nansum(vals))\n",
    "\n",
    "def try_variances(h):\n",
    "    try:\n",
    "        v = h.variances()\n",
    "        if v is not None:\n",
    "            return np.asarray(v)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def build_th1x(vals, edges, name, title, var=None):\n",
    "    vals = np.asarray(vals, dtype=\"float64\")\n",
    "    edges = np.asarray(edges, dtype=\"float64\")\n",
    "    nbins = len(edges) - 1\n",
    "    data = np.zeros(nbins + 2, dtype=\"float64\")\n",
    "    data[1:-1] = vals\n",
    "    if var is None:\n",
    "        sumw2_core = vals.copy()\n",
    "    else:\n",
    "        sumw2_core = np.asarray(var, dtype=\"float64\")\n",
    "    sumw2 = np.zeros(nbins + 2, dtype=\"float64\")\n",
    "    sumw2[1:-1] = sumw2_core\n",
    "    centers = 0.5 * (edges[1:] + edges[:-1])\n",
    "    fEntries = float(np.sum(vals))\n",
    "    fTsumw   = float(np.sum(vals))\n",
    "    fTsumw2  = float(np.sum(sumw2_core))\n",
    "    fTsumwx  = float(np.sum(vals * centers))\n",
    "    fTsumwx2 = float(np.sum(vals * centers**2))\n",
    "    xaxis = to_TAxis(\"xaxis\", \"\", nbins, float(edges[0]), float(edges[-1]), edges)\n",
    "    fMaximum = float(np.max(vals) * 1.2) if np.max(vals) > 0 else 1.0\n",
    "    fMinimum = 0.0\n",
    "    fBarOffset = 0\n",
    "    fBarWidth = 1\n",
    "    try:\n",
    "        return to_TH1x(\n",
    "            name, title, data,\n",
    "            fEntries, fTsumw, fTsumw2, fTsumwx, fTsumwx2,\n",
    "            sumw2, xaxis,\n",
    "            None, None,\n",
    "            None,\n",
    "            fBarOffset, fBarWidth,\n",
    "            fMaximum, fMinimum,\n",
    "        )\n",
    "    except TypeError:\n",
    "        return to_TH1x(\n",
    "            name, title, data,\n",
    "            fEntries, fTsumw, fTsumw2, fTsumwx, fTsumwx2,\n",
    "            sumw2, xaxis\n",
    "        )\n",
    "\n",
    "items = extract_samples_from_json(JSON_FILE)\n",
    "everything_roots = [f\"everything_merged_{s}__{c}.root\" for (s, c) in items]\n",
    "\n",
    "req_ttbar_me = \"everything_merged_ttbar__ME_var.root\"\n",
    "req_ttbar_ps = \"everything_merged_ttbar__PS_var.root\"\n",
    "req_wjets_no = \"everything_merged_wjets__nominal.root\"\n",
    "\n",
    "with uproot.recreate(\"histograms_merged.root\") as f_out:\n",
    "    for h_file in everything_roots:\n",
    "        try:\n",
    "            with uproot.open(h_file) as f_in:\n",
    "                for key in f_in.keys(cycle=False):\n",
    "                    f_out[key] = f_in[key]\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[WARN] missing: {h_file}\")\n",
    "    if all(p in everything_roots for p in (req_ttbar_me, req_ttbar_ps, req_wjets_no)):\n",
    "        with uproot.open(req_ttbar_me) as f_ttbar_ME, \\\n",
    "             uproot.open(req_ttbar_ps) as f_ttbar_PS, \\\n",
    "             uproot.open(req_wjets_no) as f_wjets:\n",
    "            ttbar_me_map = list_channel_keys(f_ttbar_ME, \"ttbar_ME_var\")\n",
    "            ttbar_ps_map = list_channel_keys(f_ttbar_PS, \"ttbar_PS_var\")\n",
    "            wjets_map    = list_channel_keys(f_wjets,    \"wjets_nominal\")\n",
    "            common_channels = sorted(set(ttbar_me_map) & set(ttbar_ps_map) & set(wjets_map))\n",
    "            print(f\"[INFO] channels for pseudodata_nominal: {len(common_channels)}\")\n",
    "            for channel in common_channels:\n",
    "                h_me = f_ttbar_ME[ttbar_me_map[channel]]\n",
    "                h_ps = f_ttbar_PS[ttbar_ps_map[channel]]\n",
    "                h_wj = f_wjets[wjets_map[channel]]\n",
    "                if (\n",
    "                    h_sum_yield(h_me) <= EMPTY_HIST_YIELD or\n",
    "                    h_sum_yield(h_ps) <= EMPTY_HIST_YIELD or\n",
    "                    h_sum_yield(h_wj) <= EMPTY_HIST_YIELD\n",
    "                ):\n",
    "                    continue\n",
    "                vals_me, edges    = h_me.to_numpy()\n",
    "                vals_ps, edges_ps = h_ps.to_numpy()\n",
    "                vals_wj, edges_wj = h_wj.to_numpy()\n",
    "                if not (np.allclose(edges, edges_ps) and np.allclose(edges, edges_wj)):\n",
    "                    print(f\"[WARN] binning mismatch in {channel}, skipping\")\n",
    "                    continue\n",
    "                new_vals = 0.5 * (vals_me + vals_ps) + vals_wj\n",
    "                var_me = try_variances(h_me)\n",
    "                var_ps = try_variances(h_ps)\n",
    "                var_wj = try_variances(h_wj)\n",
    "                new_var = 0.25 * (var_me + var_ps) + var_wj if (var_me is not None and var_ps is not None and var_wj is not None) else None\n",
    "                hname  = f\"{channel}_pseudodata_nominal\"\n",
    "                htitle = \"Pseudodata = 0.5*(ttbar_ME + ttbar_PS) + wjets_nominal\"\n",
    "                f_out[hname] = build_th1x(new_vals, edges, hname, htitle, new_var)\n",
    "\n",
    "print(\"[OK] histograms_merged.root created with pseudodata added.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
